{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7soN8NPPrB0D"
      },
      "source": [
        "# CHATBOT PARA FUNDOS IMOBILIÁRIOS\n",
        "\n",
        "## Resumo do projeto\n",
        "\n",
        "- Este projeto consiste em fazer scraping de PDFs que contêm informações sobre fundos imobiliários de algumas empresas (um total de 20). Em seguida, aplica-se uma técnica de prompt engineering para que o modelo siga determinados padrões de especialistas antes de iniciar a conversação com o usuário.\n",
        "- Quando a conversa é finalizada com a mensagem \"Finalizar\", os dados são enviados para...\n",
        "\n",
        "## Sumário\n",
        "\n",
        "    - SETUP\n",
        "    - SCRAPPING\n",
        "    - CHATBOT \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk2OwjDYN6ZJ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uug1lUbq0y2"
      },
      "source": [
        "- Instalando algumas biblioteca necessárias e importando as mesmas para o projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtgTPkKNPbSn",
        "outputId": "c3fdbecf-5af4-4784-d76d-3539f6a20958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# execute se estiver no google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M-5rVTsGIwCn"
      },
      "outputs": [],
      "source": [
        "# execute se estiver no google colab - caso não, instale o requirements disponível no GITHUB\n",
        "!pip install -q -U google-generativeai transformers pyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g7tYttzOW5l"
      },
      "source": [
        "# Scrapping PDF's Ativos\n",
        "\n",
        "Aqui é feio o scrapping dos pdf's, você pode está adquirindo os pdf's para teste a partir do link do drive:\n",
        "\n",
        "https://drive.google.com/file/d/1yVUev7Z4GwPFSUtUCN-Ky3xX3XZgRamt/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Q2CSZLBQOrDX"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "class ExtratorZip:\n",
        "    def __init__(self, arquivo_zip, pasta_destino):\n",
        "        self.arquivo_zip = arquivo_zip\n",
        "        self.pasta_destino = pasta_destino\n",
        "\n",
        "    def extrair(self):\n",
        "        with zipfile.ZipFile(self.arquivo_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.pasta_destino)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "7BtFyJ_mOv38"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "\n",
        "class PDFExtractor:\n",
        "    def __init__(self, pdf_directory, output_csv):\n",
        "        self.pdf_directory = pdf_directory\n",
        "        self.output_csv = output_csv\n",
        "\n",
        "    def preprocess_text(self, texto):\n",
        "        return ''.join((c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn'))\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_file):\n",
        "        texto = \"\"\n",
        "        with open(pdf_file, 'rb') as arquivo_pdf:\n",
        "            leitor = PyPDF2.PdfReader(arquivo_pdf)\n",
        "            for pagina in range(len(leitor.pages)):\n",
        "                texto_pagina = leitor.pages[pagina].extract_text()\n",
        "                texto += self.preprocess_text(texto_pagina)\n",
        "        texto = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff]', '', texto)\n",
        "        return texto\n",
        "\n",
        "    def scrape_pdf_directory(self):\n",
        "        with open(self.output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            fieldnames = ['arquivo', 'transcricao']\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "\n",
        "            for filename in os.listdir(self.pdf_directory):\n",
        "                if filename.endswith('.pdf'):\n",
        "                    pdf_file = os.path.join(self.pdf_directory, filename)\n",
        "                    texto = self.extract_text_from_pdf(pdf_file)\n",
        "                    writer.writerow({'arquivo': filename, 'transcricao': texto})\n",
        "\n",
        "    def extract_data_from_text(self, texto): # bem bagunçado\n",
        "        atualizacao_list = []\n",
        "        nome_pregao_list = []\n",
        "        atividade_principal_list = []\n",
        "        classificacao_setorial_list = []\n",
        "        site_list = []\n",
        "        codigos_negociacao_list = []\n",
        "        cnpj_list = []\n",
        "        ativo_imobilizado_list = []\n",
        "        ativo_total_list = []\n",
        "        patrimonio_liquido_list = []\n",
        "        lucro_prejuizo_list = []\n",
        "        atividades_operacionais_list = []\n",
        "        atividades_investimento_list = []\n",
        "        variacao_cambial_list = []\n",
        "        aumento_reducao_caixa_list = []\n",
        "        pessoas_fisicas_list = []\n",
        "        pessoas_juridicas_list = []\n",
        "        investidores_institucionais_list = []\n",
        "        acoes_ordinarias_list = []\n",
        "        acoes_preferenciais_list = []\n",
        "        total_acoes_list = []\n",
        "\n",
        "        padrao_data = re.search(r\"Atualizado em (\\d{2}/\\d{2}/\\d{4})\", texto)\n",
        "        if padrao_data:\n",
        "            atualizacao = padrao_data.group(1)\n",
        "        else:\n",
        "            atualizacao = None\n",
        "\n",
        "        padrao_nome_pregao = re.search(r\"Nome de Pregao: (.+?)\\n\", texto)\n",
        "        if padrao_nome_pregao:\n",
        "            nome_pregao = padrao_nome_pregao.group(1).lower()\n",
        "        else:\n",
        "            nome_pregao = None\n",
        "\n",
        "        padrao_atividade_principal = re.search(r\"Atividade Principal:(.+?)\\n\", texto)\n",
        "        if padrao_atividade_principal:\n",
        "            atividade_principal = padrao_atividade_principal.group(1).strip()\n",
        "        else:\n",
        "            atividade_principal = None\n",
        "\n",
        "        padrao_classificacao_setorial = re.search(r\"Setorial:(.+?)\\n\", texto)\n",
        "        if padrao_classificacao_setorial:\n",
        "            classificacao_setorial = padrao_classificacao_setorial.group(1).strip()\n",
        "            padrao_linha_adicional = re.search(r\"Setorial:(.+?)\\n(.+?)\\n\", texto, re.DOTALL)\n",
        "            if padrao_linha_adicional:\n",
        "                classificacao_setorial += \"\\n\" + padrao_linha_adicional.group(2).strip()\n",
        "        else:\n",
        "            classificacao_setorial = None\n",
        "\n",
        "        padrao_site = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', texto)\n",
        "        if padrao_site:\n",
        "            site = padrao_site[0].replace('\\\\', '')\n",
        "        else:\n",
        "            site = None\n",
        "\n",
        "        padrao_codigos_negociacao = re.findall(r\"Negociacao:(.+?)(?=CNPJ)\", texto, re.DOTALL)\n",
        "        if padrao_codigos_negociacao:\n",
        "            codigos_negociacao = [codigo.strip() for codigo in padrao_codigos_negociacao[0].split('\\n') if codigo.strip()]\n",
        "        else:\n",
        "            codigos_negociacao = None\n",
        "        padrao_cnpj = re.search(r\"CNPJ: (\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})\", texto)\n",
        "        if padrao_cnpj:\n",
        "            cnpj = padrao_cnpj.group(1)\n",
        "        else:\n",
        "            cnpj = None\n",
        "        padrao_ativos_imobilizado = re.search(r\"Ativo Imobilizado, Investimentos e Intang.*?([\\d.,]+)\\s+([\\d.,]+)\", texto)\n",
        "        ativo_imobilizado = padrao_ativos_imobilizado.group(1).replace('.', '').replace(',', '.') if padrao_ativos_imobilizado else None\n",
        "        padrao_ativos_total = re.search(r\"Ativo To.*?([\\d.,]+)\\s+([\\d.,]+)\", texto)\n",
        "        ativo_total = None\n",
        "        padrao_ativos_total = re.search(r\"Ativo To.*?([\\d.,]+)\\s+([\\d.,]+)\", texto)\n",
        "        ativo_total_match = padrao_ativos_total.group(1) if padrao_ativos_total else None\n",
        "        if ativo_total_match:\n",
        "            if \"bilh\" in ativo_total_match.lower():\n",
        "                ativo_total = float(ativo_total_match.replace(\"bilh\", \"\").replace(\".\", \"\").replace(\",\", \".\")) * 10**9\n",
        "            else:\n",
        "                ativo_total = ativo_total_match.replace('.', '').replace(',', '.')\n",
        "\n",
        "        padrao_patrimonio_liquido = re.search(r\"Patrimonio Liquido.*?([\\d.,]+)\\s+([\\d.,]+)\", texto)\n",
        "        patrimonio_liquido = padrao_patrimonio_liquido.group(1).replace('.', '').replace(',', '.') if padrao_patrimonio_liquido else None\n",
        "        padrao_lucro_prejuizo = re.search(r\"Lucro \\(Prejuizo\\) do Periodo\\s*[\\(\\)]*\\s*([\\d.,]+)\", texto)\n",
        "        lucro_prejuizo = padrao_lucro_prejuizo.group(1).replace('.', '').replace(',', '.') if padrao_lucro_prejuizo else None\n",
        "        padrao_patrimonio_liquido = re.search(r\"Patrimonio Liquido.*?([\\d.,]+)\", texto)\n",
        "        patrimonio_liquido = padrao_patrimonio_liquido.group(1).replace('.', '').replace(',', '.') if padrao_patrimonio_liquido else None\n",
        "        padrao_operacionais = re.search(r\"Atividades Operacionais\\s*\\(*([\\d.,\\-\\s]+)\\)*\", texto)\n",
        "        atividades_operacionais = re.search(r\"[\\d.,]+\", padrao_operacionais.group(1).replace(',', '.')) if padrao_operacionais else None\n",
        "        atividades_operacionais = float(atividades_operacionais.group().replace('.', '').replace(',', '.')) if atividades_operacionais else None\n",
        "\n",
        "        padrao_investimento = re.search(r\"Atividades de Investimento\\s*\\(*([\\d.,\\-\\s]+)\\)*\", texto)\n",
        "        atividades_investimento = padrao_investimento.group(1).replace('(', '').replace(')', '').replace('.', '').replace(',', '.') if padrao_investimento else None\n",
        "        padrao_variacao_cambial = re.search(r\"Variacao Cambial sobre Caixa e Equivalentes\\s*\\(*([\\d.,\\-\\s]+)\\)*\", texto)\n",
        "        variacao_cambial = re.findall(r\"-?\\d+\\.\\d+\", padrao_variacao_cambial.group(1).replace(',', '.')) if padrao_variacao_cambial else None\n",
        "        variacao_cambial = float(variacao_cambial[0]) if variacao_cambial else None\n",
        "        padrao_aumento_reducao = re.search(r\"Aumento \\(Reducao\\) de Caixa e Equivalentes\\s*\\(*([\\d.,\\-\\s]+)\\)*\", texto)\n",
        "        aumento_reducao_caixa = re.findall(r\"-?\\d+\\.\\d+\", padrao_aumento_reducao.group(1).replace(',', '.')) if padrao_aumento_reducao else None\n",
        "        aumento_reducao_caixa = float(aumento_reducao_caixa[0]) if aumento_reducao_caixa else None\n",
        "        padrao_pessoas_fisicas = re.search(r\"Pessoas Fisicas\\s*([\\d.,\\-\\s]+)\", texto)\n",
        "        pessoas_fisicas = padrao_pessoas_fisicas.group(1).strip().replace(\"-\",\"\") if padrao_pessoas_fisicas else None\n",
        "        padrao_pessoas_juridicas = re.search(r\"Pessoas Juridicas\\s*([\\d.,\\-\\s]+)\", texto)\n",
        "        pessoas_juridicas = padrao_pessoas_juridicas.group(1).strip().replace(\"-\",\"\") if padrao_pessoas_juridicas else None\n",
        "        padrao_investidores_institucionais = re.search(r\"Investidores Institucionais\\s*([\\d.,\\-\\s]+)\", texto)\n",
        "        investidores_institucionais = padrao_investidores_institucionais.group(1).replace('-', '').strip() if padrao_investidores_institucionais else None\n",
        "        padrao_acoes_ordinarias = re.search(r\"Quantidade de Acoes Ordinarias\\s*([\\d.,\\-\\s]+)\", texto)\n",
        "        acoes_ordinarias = re.search(r\"[\\d.,]+\", padrao_acoes_ordinarias.group(1)).group() if padrao_acoes_ordinarias else None\n",
        "        padrao_acoes_preferenciais = re.search(r\"Quantidade de Acoes Preferenciais\\s*([\\d.,\\-\\s]+)\", texto)\n",
        "        acoes_preferenciais = padrao_acoes_preferenciais.group(1).replace('-', '').strip() if padrao_acoes_preferenciais else None\n",
        "        padrao_total_acoes = re.search(r\"Total de Acoes\\s*([\\d.,]+)\", texto)\n",
        "        total_acoes = padrao_total_acoes.group(1) if padrao_total_acoes else None\n",
        "        padrao_acoes = re.findall(r\"(Ordinárias|Preferenciais|Total)\\s*([\\d.,]+)\", texto)\n",
        "        informacoes_acoes = {}\n",
        "        for acao, quantidade in padrao_acoes:\n",
        "            informacoes_acoes[acao] = quantidade\n",
        "\n",
        "        # adiciona as informações às listas\n",
        "        atualizacao_list.append(atualizacao)\n",
        "        nome_pregao_list.append(nome_pregao)\n",
        "        atividade_principal_list.append(atividade_principal)\n",
        "        classificacao_setorial_list.append(classificacao_setorial)\n",
        "        site_list.append(site)\n",
        "        codigos_negociacao_list.append(codigos_negociacao)\n",
        "        cnpj_list.append(cnpj)\n",
        "        ativo_imobilizado_list.append(ativo_imobilizado)\n",
        "        ativo_total_list.append(ativo_total)\n",
        "        patrimonio_liquido_list.append(patrimonio_liquido)\n",
        "        lucro_prejuizo_list.append(lucro_prejuizo)\n",
        "        atividades_operacionais_list.append(atividades_operacionais)\n",
        "        atividades_investimento_list.append(atividades_investimento)\n",
        "        variacao_cambial_list.append(variacao_cambial)\n",
        "        aumento_reducao_caixa_list.append(aumento_reducao_caixa)\n",
        "        pessoas_fisicas_list.append(pessoas_fisicas)\n",
        "        pessoas_juridicas_list.append(pessoas_juridicas)\n",
        "        investidores_institucionais_list.append(investidores_institucionais)\n",
        "        acoes_ordinarias_list.append(acoes_ordinarias)\n",
        "        acoes_preferenciais_list.append(acoes_preferenciais)\n",
        "        total_acoes_list.append(total_acoes)\n",
        "\n",
        "        # Retornando os dados\n",
        "        return {\n",
        "            'Atualizacao': atualizacao_list,\n",
        "            'Nome Pregao': nome_pregao_list,\n",
        "            'Atividade Principal': atividade_principal_list,\n",
        "            'Classificacao Setorial': classificacao_setorial_list,\n",
        "            'Site': site_list,\n",
        "            'Codigos Negociacao': codigos_negociacao_list,\n",
        "            'CNPJ': cnpj_list,\n",
        "            'Imobilizado': ativo_imobilizado_list,\n",
        "            'Total': ativo_total_list,\n",
        "            'Patrimonio Liquido': patrimonio_liquido_list,\n",
        "            'Lucro Prejuizo': lucro_prejuizo_list,\n",
        "            'Operacionais': atividades_operacionais_list,\n",
        "            'Investimento': atividades_investimento_list,\n",
        "            'Variacao Cambial': variacao_cambial_list,\n",
        "            'Aumento Reducao Caixa': aumento_reducao_caixa_list,\n",
        "            'Fisicas': pessoas_fisicas_list,\n",
        "            'Juridicas': pessoas_juridicas_list,\n",
        "            'Investidores Institucionais': investidores_institucionais_list,\n",
        "            'Ordinarias': acoes_ordinarias_list,\n",
        "            'Preferenciais': acoes_preferenciais_list,\n",
        "            'Total Acoes': total_acoes_list\n",
        "        }\n",
        "\n",
        "    def process_pdf_data(self):\n",
        "        df_final = pd.DataFrame(columns=[\n",
        "            'Atualizacao',\n",
        "            'Nome Pregao',\n",
        "            'Atividade Principal',\n",
        "            'Classificacao Setorial',\n",
        "            'Site',\n",
        "            'Codigos Negociacao',\n",
        "            'CNPJ',\n",
        "            'Imobilizado',\n",
        "            'Total',\n",
        "            'Patrimonio Liquido',\n",
        "            'Lucro Prejuizo',\n",
        "            'Operacionais',\n",
        "            'Investimento',\n",
        "            'Variacao Cambial',\n",
        "            'Aumento Reducao Caixa',\n",
        "            'Fisicas',\n",
        "            'Juridicas',\n",
        "            'Investidores Institucionais',\n",
        "            'Ordinarias',\n",
        "            'Preferenciais',\n",
        "            'Total Acoes'\n",
        "        ])\n",
        "\n",
        "        for filename in os.listdir(self.pdf_directory):\n",
        "            if filename.endswith('.pdf'):\n",
        "                pdf_file = os.path.join(self.pdf_directory, filename)\n",
        "                texto = self.extract_text_from_pdf(pdf_file)\n",
        "                dados = self.extract_data_from_text(texto)\n",
        "                df_temp = pd.DataFrame(dados)\n",
        "                df_final = pd.concat([df_final, df_temp], ignore_index=True)\n",
        "\n",
        "        caminho_arquivo_final = 'files/dados_extraidos_final.csv'\n",
        "        df_final.to_csv(caminho_arquivo_final, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "iHBx02Z3Ox1K"
      },
      "outputs": [],
      "source": [
        "# Função complementar para os dados, para que se possa utilizar formato json ou csv\n",
        "\n",
        "import csv\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from transformers import pipeline\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv_file = csv_file\n",
        "        self.data = None\n",
        "\n",
        "    def read_csv_to_json(self):\n",
        "        with open(self.csv_file, 'r', encoding='utf-8') as file:\n",
        "            reader = csv.DictReader(file)\n",
        "            self.data = [row for row in reader]\n",
        "\n",
        "    def write_json(self, json_file):\n",
        "        with open(json_file, 'w', encoding='utf-8') as file:\n",
        "            json.dump(self.data, file, indent=4)\n",
        "\n",
        "    def read_json(self, json_file):\n",
        "        with open(json_file, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "    def restructure_data(self):\n",
        "        restructured_data = defaultdict(list)\n",
        "        for row in self.data:\n",
        "            for key, value in row.items():\n",
        "                restructured_data[key].append(value)\n",
        "        self.data = restructured_data\n",
        "\n",
        "    def query_data(self, query):\n",
        "        table = pd.DataFrame.from_dict(self.data)\n",
        "        tqa = pipeline(task=\"table-question-answering\", model=\"google/tapas-large-finetuned-wtq\")\n",
        "        results = tqa(table=table, query=query)\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBGBifWwsR4e"
      },
      "source": [
        "- Aqui realiza de fato o scrapping, chamando as funções anteriormente criadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztj2gULxOzdN",
        "outputId": "7c23f3a0-fd05-4949-e996-be81fcd38c50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_22110/548116146.py:230: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_final = pd.concat([df_final, df_temp], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "def scrapping():\n",
        "    # extrair arquivos ZIP\n",
        "    extrator = ExtratorZip(\"files/ativos.zip\", \"files/\")\n",
        "    extrator.extrair()\n",
        "\n",
        "    # extrair texto de arquivos PDF e salvar em CSV\n",
        "    extrator_pdf = PDFExtractor(\"files/ativos\", \"files/output.csv\")\n",
        "    extrator_pdf.scrape_pdf_directory()\n",
        "\n",
        "    # processar dados dos arquivos PDF e salvar em um arquivo CSV final\n",
        "    extrator_pdf.process_pdf_data()\n",
        "\n",
        "    # formatos dos arquivos\n",
        "    processador = DataProcessor(\"files/dados_extraidos_final.csv\")\n",
        "    processador.read_csv_to_json()\n",
        "    processador.restructure_data()\n",
        "    processador.write_json(\"files/output.json\")\n",
        "    processador.read_json(\"files/output.json\")\n",
        "\n",
        "\n",
        "scrapping()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-nBEOgIQBZW"
      },
      "source": [
        "# Gemini Google - ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmRw4z3_s_Nh"
      },
      "source": [
        "- Chamei o arquivo de saída no formato JSON e forneci um prompt padrão para o modelo para que siga determinadas diretrizes.\n",
        "\n",
        "- DEFINA SUA API KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RKcwEolVOBfT"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=''  # provisória\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2So12aoYOF0u"
      },
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 1,\n",
        "}\n",
        "# safety_settings = {\n",
        "#     \"HARASSMENT\": \"BLOCK_SOME\",\n",
        "#     \"HATE\": \"BLOCK_SOME\",\n",
        "#     \"SEXUAL\": \"BLOCK_SOME\",\n",
        "#     \"DANGEROUS\": \"BLOCK_SOME\",\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OUmy9txvQWro"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                              generation_config=generation_config,\n",
        "                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WD5xoMF4R11n"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('files/output.json') as arquivo_json:\n",
        "    dados = json.load(arquivo_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_inicial = f\"Aja como uma especialista em fundos imobiliários, criativo e descritivo, respondendo apenas com as informações fornecidas: {dados} ------ Caso o usário pergunte sobre outros assuntos responda: Não posso lhe responder sobre este assunto, me pergunte sobre fundos imobiliários.\"\n",
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypFJiIgtQO_g"
      },
      "outputs": [],
      "source": [
        "print('Fundos Imobiliários Disponiveis:')\n",
        "for i in dados['Nome Pregao']:\n",
        "  print(i)\n",
        "prompt = input(\"Esperando Prompt: \").lower()\n",
        "\n",
        "while prompt != \"finalizar\":\n",
        "  response = chat.send_message(prompt_inicial + prompt).lower()\n",
        "  print('Resposta: ', response.text)\n",
        "  prompt = input(\"Esperando Prompt: \")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
